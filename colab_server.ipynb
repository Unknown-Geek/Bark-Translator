{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "unique_id_here"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install flask transformers torch pillow flask-cors accelerate pyngrok\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from PIL import Image\n",
    "import io\n",
    "from pyngrok import ngrok, conf\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app, resources={r\"/*\": {\"origins\": \"*\"}})\n",
    "\n",
    "# Configure ngrok\n",
    "NGROK_AUTH_TOKEN = \"2oHUyMyGNJuD34GO6NdGJd8KAxd_3TyYzUGLMA9DvgUopNRw3\"\n",
    "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
    "\n",
    "try:\n",
    "    print('Loading AI models...')\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    # Load BLIP for image captioning\n",
    "    image_captioner = pipeline(\"image-to-text\", model=\"Salesforce/blip-image-captioning-base\", device=device)\n",
    "    \n",
    "    # Load GPT-2 for story generation\n",
    "    story_model_name = \"gpt2\"\n",
    "    story_tokenizer = AutoTokenizer.from_pretrained(story_model_name)\n",
    "    story_model = AutoModelForCausalLM.from_pretrained(story_model_name).to(device)\n",
    "    \n",
    "    print(f'Models loaded successfully on {device}!')\n",
    "    \n",
    "    def generate_horror_story(caption):\n",
    "        \"\"\"Generate a horror story using GPT-2\"\"\"\n",
    "        prompt = f\"\"\"Scene: {caption}\\n\\nA spooky horror story based on this scene:\\n\\n\"\"\"\n",
    "        \n",
    "        inputs = story_tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "        \n",
    "        outputs = story_model.generate(\n",
    "            inputs,\n",
    "            max_length=300,\n",
    "            num_return_sequences=1,\n",
    "            pad_token_id=story_tokenizer.eos_token_id,\n",
    "            do_sample=True,\n",
    "            temperature=0.9,\n",
    "            top_k=50,\n",
    "            top_p=0.95,\n",
    "            no_repeat_ngram_size=2,\n",
    "            num_beams=4\n",
    "        )\n",
    "        \n",
    "        story = story_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        return story[len(prompt):].strip()\n",
    "    \n",
    "    @app.after_request\n",
    "    def after_request(response):\n",
    "        response.headers.add('Access-Control-Allow-Origin', '*')\n",
    "        response.headers.add('Access-Control-Allow-Headers', 'Content-Type')\n",
    "        response.headers.add('Access-Control-Allow-Methods', 'GET,POST,OPTIONS')\n",
    "        response.headers.add('Connection', 'close')\n",
    "        return response\n",
    "    \n",
    "    @app.route('/generate_story', methods=['POST', 'OPTIONS'])\n",
    "    def generate_story():\n",
    "        if request.method == 'OPTIONS':\n",
    "            return '', 204\n",
    "        try:\n",
    "            if 'image' not in request.files:\n",
    "                return jsonify({'status': 'error', 'message': 'No image provided'}), 400\n",
    "                \n",
    "            image_file = request.files['image']\n",
    "            image = Image.open(io.BytesIO(image_file.read()))\n",
    "            \n",
    "            caption = image_captioner(image)[0]['generated_text']\n",
    "            story = generate_horror_story(caption)\n",
    "            \n",
    "            return jsonify({\n",
    "                'status': 'success',\n",
    "                'caption': caption,\n",
    "                'story': story\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            return jsonify({'status': 'error', 'message': str(e)}), 500\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error setting up server: {str(e)}\")\n",
    "    raise e\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Start ngrok when the app starts\n",
    "    ngrok.kill()  # Kill any existing tunnels\n",
    "    public_url = ngrok.connect(\n",
    "        addr=5000,\n",
    "        proto=\"http\"  # Force HTTP protocol\n",
    "    )\n",
    "    print(f'Ngrok tunnel established! Public URL: {public_url}')\n",
    "    # Run app locally\n",
 "metadata": {
  "colab": {
   "name": "Horror Story Generator API",
   "private_outputs": true
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
